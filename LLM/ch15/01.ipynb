{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4537345a",
   "metadata": {},
   "source": [
    "#### 미세조정 전 후 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f540574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰: 1 : This movie is absolutely amazing! Best film I've ever seen.\n",
      "예측 : 긍정 0.6370\n",
      "긍정 확률 : 0.6370, 부정 확률 : 0.3630\n",
      "리뷰: 2 : Terrible waste of time. Worst movie ever made.\n",
      "예측 : 긍정 0.6137\n",
      "긍정 확률 : 0.6137, 부정 확률 : 0.3863\n",
      "리뷰: 3 : It was okay, nothing special but not bad either.\n",
      "예측 : 긍정 0.5955\n",
      "긍정 확률 : 0.5955, 부정 확률 : 0.4045\n",
      "리뷰: 4 : Brilliant acting and stunning visuals throughout!\n",
      "예측 : 긍정 0.6267\n",
      "긍정 확률 : 0.6267, 부정 확률 : 0.3733\n",
      "리뷰: 5 : Boring and predictable plot. Very disappointed.\n",
      "예측 : 긍정 0.6133\n",
      "긍정 확률 : 0.6133, 부정 확률 : 0.3867\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "test_reviews = [\n",
    "    \"This movie is absolutely amazing! Best film I've ever seen.\",\n",
    "    \"Terrible waste of time. Worst movie ever made.\",\n",
    "    \"It was okay, nothing special but not bad either.\",\n",
    "    \"Brilliant acting and stunning visuals throughout!\",\n",
    "    \"Boring and predictable plot. Very disappointed.\"\n",
    "]\n",
    "\n",
    "labels = [\"부정\", \"긍정\"]\n",
    "\n",
    "# 미세 조정전 모델(랜덤 초기화)\n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "model_before = AutoModelForSequenceClassification.from_pretrained(BERT_MODEL_NAME)\n",
    "model_before.eval()\n",
    "with torch.no_grad():\n",
    "    for i ,review in enumerate(test_reviews):\n",
    "        inputs = tokenizer(review, return_tensors='pt')\n",
    "        logits = model_before(**inputs).logits\n",
    "        probs = torch.softmax(logits, dim=-1)[0]\n",
    "        pred_label = logits.argmax().item()\n",
    "\n",
    "        print(f'리뷰: {i+1} : {review}')\n",
    "        print(f'예측 : {labels[pred_label]} {probs[pred_label]:.4f}')\n",
    "        print(f'긍정 확률 : {probs[1]:.4f}, 부정 확률 : {probs[0]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9517c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰: 1 : This movie is absolutely amazing! Best film I've ever seen.\n",
      "예측 : 긍정 0.8490\n",
      "긍정 확률 : 0.8490, 부정 확률 : 0.1510\n",
      "리뷰: 2 : Terrible waste of time. Worst movie ever made.\n",
      "예측 : 부정 0.8977\n",
      "긍정 확률 : 0.1023, 부정 확률 : 0.8977\n",
      "리뷰: 3 : It was okay, nothing special but not bad either.\n",
      "예측 : 부정 0.6330\n",
      "긍정 확률 : 0.3670, 부정 확률 : 0.6330\n",
      "리뷰: 4 : Brilliant acting and stunning visuals throughout!\n",
      "예측 : 긍정 0.8958\n",
      "긍정 확률 : 0.8958, 부정 확률 : 0.1042\n",
      "리뷰: 5 : Boring and predictable plot. Very disappointed.\n",
      "예측 : 부정 0.8304\n",
      "긍정 확률 : 0.1696, 부정 확률 : 0.8304\n"
     ]
    }
   ],
   "source": [
    "train_texts = [\n",
    "    (\"This is wonderful and fantastic!\", 1),  # 긍정\n",
    "    (\"Absolutely terrible and awful!\", 0),     # 부정\n",
    "    (\"I love this so much!\", 1),\n",
    "    (\"Hated it completely!\", 0)\n",
    "]\n",
    "\n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "model_after = AutoModelForSequenceClassification.from_pretrained(BERT_MODEL_NAME, num_labels=2)\n",
    "from torch.optim import AdamW\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "optimizer = AdamW(model_after.parameters(), lr=5e-5)\n",
    "model_after.train()\n",
    "for epoch in range(5):\n",
    "    for text, label in train_texts:\n",
    "        inputs = tokenizer(text, return_tensors='pt')\n",
    "        labels_tensor = torch.tensor([label])\n",
    "        outputs = model_after(**inputs, labels=labels_tensor)\n",
    "        loss = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "model_after.eval()\n",
    "with torch.no_grad():\n",
    "    for i ,review in enumerate(test_reviews):\n",
    "        inputs = tokenizer(review, return_tensors='pt')\n",
    "        logits = model_after(**inputs).logits\n",
    "        probs = torch.softmax(logits, dim=-1)[0]\n",
    "        pred_label = logits.argmax().item()\n",
    "\n",
    "        print(f'리뷰: {i+1} : {review}')\n",
    "        print(f'예측 : {labels[pred_label]} {probs[pred_label]:.4f}')\n",
    "        print(f'긍정 확률 : {probs[1]:.4f}, 부정 확률 : {probs[0]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd4e3529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Collecting httpx<1.0.0 (from datasets)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Collecting anyio (from httpx<1.0.0->datasets)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Installing collected packages: xxhash, httpcore, dill, anyio, multiprocess, httpx, datasets\n",
      "\n",
      "   ----- ---------------------------------- 1/7 [httpcore]\n",
      "   ----- ---------------------------------- 1/7 [httpcore]\n",
      "   ----- ---------------------------------- 1/7 [httpcore]\n",
      "   ----- ---------------------------------- 1/7 [httpcore]\n",
      "   ----- ---------------------------------- 1/7 [httpcore]\n",
      "   ----- ---------------------------------- 1/7 [httpcore]\n",
      "   ----------- ---------------------------- 2/7 [dill]\n",
      "   ----------- ---------------------------- 2/7 [dill]\n",
      "   ----------- ---------------------------- 2/7 [dill]\n",
      "   ----------- ---------------------------- 2/7 [dill]\n",
      "   ----------- ---------------------------- 2/7 [dill]\n",
      "   ----------- ---------------------------- 2/7 [dill]\n",
      "   ----------- ---------------------------- 2/7 [dill]\n",
      "   ----------- ---------------------------- 2/7 [dill]\n",
      "   ----------- ---------------------------- 2/7 [dill]\n",
      "   ----------------- ---------------------- 3/7 [anyio]\n",
      "   ----------------- ---------------------- 3/7 [anyio]\n",
      "   ----------------- ---------------------- 3/7 [anyio]\n",
      "   ----------------- ---------------------- 3/7 [anyio]\n",
      "   ----------------- ---------------------- 3/7 [anyio]\n",
      "   ----------------- ---------------------- 3/7 [anyio]\n",
      "   ---------------------- ----------------- 4/7 [multiprocess]\n",
      "   ---------------------- ----------------- 4/7 [multiprocess]\n",
      "   ---------------------- ----------------- 4/7 [multiprocess]\n",
      "   ---------------------- ----------------- 4/7 [multiprocess]\n",
      "   ---------------------- ----------------- 4/7 [multiprocess]\n",
      "   ---------------------- ----------------- 4/7 [multiprocess]\n",
      "   ---------------------- ----------------- 4/7 [multiprocess]\n",
      "   ---------------------- ----------------- 4/7 [multiprocess]\n",
      "   ---------------------------- ----------- 5/7 [httpx]\n",
      "   ---------------------------- ----------- 5/7 [httpx]\n",
      "   ---------------------------- ----------- 5/7 [httpx]\n",
      "   ---------------------------- ----------- 5/7 [httpx]\n",
      "   ---------------------------- ----------- 5/7 [httpx]\n",
      "   ---------------------------- ----------- 5/7 [httpx]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------- ----- 6/7 [datasets]\n",
      "   ---------------------------------------- 7/7 [datasets]\n",
      "\n",
      "Successfully installed anyio-4.11.0 datasets-4.4.1 dill-0.4.0 httpcore-1.0.9 httpx-0.28.1 multiprocess-0.70.18 xxhash-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f294c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6223751b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\31799\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 데이터 다운로드 \n",
    "# 라벨은 pos:1, neg:0\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import movie_reviews\n",
    "ids = movie_reviews.fileids()\n",
    "reviews = [movie_reviews.raw(fid) for fid in ids]\n",
    "labels = [1 if fid.startswith('pos') else 0 for fid in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "578f84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    reviews, labels, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67ddf77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 400)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이저\n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "# 훈련/테스트 데이터 토큰화\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512)\n",
    "len(train_encodings['input_ids']), len(test_encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2025f251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋 크기: 1600\n",
      "테스트 데이터셋 크기: 400\n"
     ]
    }
   ],
   "source": [
    "# torch dataset 구성\n",
    "class MovieReviewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "train_dataset = MovieReviewsDataset(train_encodings, train_labels)\n",
    "test_dataset = MovieReviewsDataset(test_encodings, test_labels)\n",
    "print(f'훈련 데이터셋 크기: {len(train_dataset)}')\n",
    "print(f'테스트 데이터셋 크기: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a201d4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  2096,  3666, 10916,  1010,  2009,  4158,  2000,  2033,  2008,\n",
       "          6864, 17752,  2121,  2989,  1005,  1055,  2995, 11067,  2004,  1037,\n",
       "          2143,  1011,  9338,  2003,  9179,  1012,  1999,  3435,  2335,  2012,\n",
       "          5526,  9629,  2152,  1010,  2016,  2435,  2149,  5977,  9502,  1005,\n",
       "          1055,  5076, 11867, 11261,  3669,  1025,  1999,  2298,  2040,  1005,\n",
       "          1055,  3331,  1010,  2016,  2357,  5503, 12688,  2046,  1037,  7968,\n",
       "          1011, 15729,  3336,  1998,  3024,  2198, 19817, 11431, 27914,  2050,\n",
       "          2007,  2003,  2034,  2476,  6308,  1025,  1999,  9789,  3238,  1010,\n",
       "          2016,  2179,  1037,  2732,  4316,  2005,  1996, 23677,  2791,  2008,\n",
       "          2003,  1006,  2030,  2001,  1007, 15935,  3165,  9221,  1012,  2016,\n",
       "          3849,  2000,  3305, 16607,  2129,  2000,  2424,  9567,  1996,  4378,\n",
       "          2097,  2066,  1999,  8741,  1997,  2037, 21407,  1012,  6854,  1010,\n",
       "          2016,  2089,  2036,  2022,  3225,  2000,  3305,  2008,  2016, 19821,\n",
       "          1012,  3228, 16004,  5889,  2019, 16004,  5896,  9005,  2066,  3085,\n",
       "          5691,  1012,  3228, 16004,  5889,  1037,  5896,  1999,  2029,  2037,\n",
       "          5574,  1035,  2003,  1035,  1996,  3185,  3084,  2005, 14153,  9643,\n",
       "          3152,  2066, 10916,  1012,  8100,  1010, 17752,  2121,  2989,  3084,\n",
       "          2014, 10191,  2019,  2035,  1011,  2105, 18370,  3124,  1012,  2703,\n",
       "          9092,  2638,  2243,  1006,  4463,  2502,  5620,  1007,  2003,  1037,\n",
       "          2235,  1011,  2237,  2879,  2040,  4152,  1037,  6566,  2000, 27935,\n",
       "          1010,  2059,  6880,  4858,  2370,  2019,  2479,  1997, 15398,  1998,\n",
       "         29454, 29206,  3401,  1999,  1996,  3147,  1011, 18627,  2502,  2103,\n",
       "          1012,  2703,  2003,  1996,  2785,  1997,  3124,  2040,  3957,  2039,\n",
       "          2010,  2835,  2006,  1996, 10798,  2000,  2019,  9750,  2450,  1025,\n",
       "          2010, 18328,  2015,  4205,  1006, 23564,  2243,  2030,  2705,  1007,\n",
       "          1010,  3782,  1006,  3419,  6517,  2891,  3211,  1007,  1998,  7240,\n",
       "          1006,  3958,  4328,  9304,  1007,  2024,  1996,  2785,  1997,  4364,\n",
       "          2040,  8479,  2037,  2189,  1998,  2292,  2037,  2300,  8270,  2015,\n",
       "         17271,  2035,  2058,  2703,  1012,  2703,  2003,  2036,  1996,  2785,\n",
       "          1997,  3124,  2040,  4748, 16610,  3057,  2013, 28978,  1010,  1999,\n",
       "          2023,  2553,  1996,  8403, 21008,  6323,  1006,  2273,  2050, 15620,\n",
       "          8486,  1007,  1012, 21008,  2038,  3471,  1997,  2014,  2219,  1010,\n",
       "          2164,  1037, 15843,  1997,  5029,  2000,  3477,  2014, 15413,  1998,\n",
       "          1037,  3276,  2007,  1037,  2934,  1010,  3487,  2632, 13124,  1006,\n",
       "          6754, 12631, 22084,  2099,  1007,  1010,  2008,  1005,  1055,  2062,\n",
       "          2084,  3621,  2028,  1011, 11536,  1012,  2027,  1005,  2128,  2048,\n",
       "          9530, 11020, 11638,  6313,  4268,  2040,  2293,  4176,  1998, 11573,\n",
       "          2111,  1010,  2061,  4415,  2027,  7141,  2362,  1010,  2130,  2065,\n",
       "          2703,  2003,  1037, 10916,  1012,  1045,  2442, 18766,  2008,  1010,\n",
       "          2005,  1037,  2096,  1010,  1045,  2001, 26476,  2098,  1999,  2011,\n",
       "         17752,  2121,  2989,  1005,  1055,  9179,  1012,  4463,  2502,  5620,\n",
       "          2003,  2019, 11973,  9256,  3005, 23693,  3504,  2191,  2032,  2130,\n",
       "          6082,  2000,  9979,  1025, 15620,  8486,  2003,  1037,  2522, 29416,\n",
       "          2007,  2019,  2104, 10841, 14343,  3372,  1997,  4454,  1012,  2027,\n",
       "          1005,  2128,  8242,  2438,  2000,  3422,  1010,  1998, 17752,  2121,\n",
       "          2989,  3957,  2149,  7564,  1997,  5019,  7411,  2129,  3835,  2027,\n",
       "          2024,  1998,  2129,  3835,  2037,  7972, 17379,  2015,  4995,  1005,\n",
       "          1056,  1012,  2059,  2009,  6360,  4150,  3154,  2008,  2045,  1005,\n",
       "          1055,  8990,  2498,  2000, 10916,  2021,  5019,  1997,  2008,  4066,\n",
       "          1012,  1999,  3399,  1010, 10916,  2003,  1037,  6298,  4038,  1010,\n",
       "          2021,  2045,  2003, 20071,  1037,  4756,  2000,  2022,  2179,  1999,\n",
       "          1996,   102]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76ef9731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파라메터수: 109483778\n",
      "학습 가능한 파라메터 : 109483778\n"
     ]
    }
   ],
   "source": [
    "# 모델 로드\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BERT_MODEL_NAME, num_labels=2)\n",
    "print(f'파라메터수: {sum(p.numel() for p in model.parameters())}')\n",
    "print(f'학습 가능한 파라메터 : {sum(p.numel() for p in model.parameters() if p.requires_grad)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05709583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e443611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (4.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (2.3.3)\n",
      "Requirement already satisfied: dill in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (0.70.18)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\31799\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 평가 매트릭스\n",
    "%pip install evaluate\n",
    "import evaluate\n",
    "metric = evaluate.load('accuracy')\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    pred = logits.argmax(axis=1)\n",
    "    return metric.compute(predictions=pred, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1d1c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (TrainingArguments, Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509fae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
